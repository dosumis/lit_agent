uv run python -m lit_agent.identifiers.validation_demo
2025-11-05 17:20:45,715 - __main__ - INFO - üîç Extracting URLs from deepsearch bibliography files...
2025-11-05 17:20:45,716 - lit_agent.identifiers.url_extractor - INFO - Extracted 0 URLs from OPENAI_ds_Astrocytes_wmb.md
2025-11-05 17:20:45,716 - lit_agent.identifiers.url_extractor - INFO - Extracted 61 URLs from Astrocytes_patch_seq_ds_perplexity.md
2025-11-05 17:20:45,716 - lit_agent.identifiers.url_extractor - INFO - Extracted 160 URLs from Perplexity_ds_astrocytes_transcriptomics_data.md
2025-11-05 17:20:45,717 - lit_agent.identifiers.url_extractor - INFO - Extracted 197 URLs from Perplexity_ds_astrocytes_markers.md
2025-11-05 17:20:45,717 - lit_agent.identifiers.url_extractor - INFO - Extracted 86 URLs from Perplexity_ds_astrocytes_WMB.md
2025-11-05 17:20:45,717 - lit_agent.identifiers.url_extractor - INFO - Extracted 504 total URLs from 5 files
2025-11-05 17:20:45,717 - lit_agent.identifiers.url_extractor - INFO - Academic URLs: 437, Non-academic: 67
2025-11-05 17:20:45,717 - lit_agent.identifiers.url_extractor - INFO - Removed 62 duplicate URLs
2025-11-05 17:20:45,717 - __main__ - INFO - üìä Sampled 100 URLs from 377 total academic URLs
2025-11-05 17:20:45,717 - __main__ - INFO - üóÇÔ∏è URL extraction stats: 5 files, 377 academic URLs
2025-11-05 17:20:45,717 - __main__ - INFO - üöÄ Starting validation assessment demo with 100 URLs
2025-11-05 17:20:45,717 - __main__ - INFO - Topic validation enabled: True
============================================================
üìä VALIDATION ASSESSMENT DEMO
============================================================
Processing 100 URLs...
Topic validation: ENABLED

/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/eutils/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
2025-11-05 17:20:46 mib119301s metapub.config[48528] WARNING NCBI_API_KEY was not set.
2025-11-05 17:20:46 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for pmc PMC8410770: module 'metapub' has no attribute 'PubMedCentralFetcher'
2025-11-05 17:20:47 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for pmc PMC10081189: module 'metapub' has no attribute 'PubMedCentralFetcher'
2025-11-05 17:20:48 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for doi 10.1038/s41598-024-74732-7: module 'metapub' has no attribute 'CrossRef'
2025-11-05 17:20:49 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for pmc PMC12141159: module 'metapub' has no attribute 'PubMedCentralFetcher'
2025-11-05 17:20:50 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for doi 10.1002/glia.20320: module 'metapub' has no attribute 'CrossRef'
2025-11-05 17:20:51 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for doi 10.1021/acschemneuro.4c00714: module 'metapub' has no attribute 'CrossRef'
2025-11-05 17:20:53 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for pmc PMC10009953: module 'metapub' has no attribute 'PubMedCentralFetcher'
2025-11-05 17:20:55 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for pmc PMC12420811: module 'metapub' has no attribute 'PubMedCentralFetcher'
2025-11-05 17:20:56 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for pmc PMC10157076: module 'metapub' has no attribute 'PubMedCentralFetcher'
2025-11-05 17:20:57 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for pmc PMC9265979: module 'metapub' has no attribute 'PubMedCentralFetcher'
2025-11-05 17:20:58 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for doi 10.1002/jnr.490160122: module 'metapub' has no attribute 'CrossRef'
2025-11-05 17:21:00 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for pmc PMC8428855: module 'metapub' has no attribute 'PubMedCentralFetcher'
2025-11-05 17:21:01 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for pmc PMC7272763: module 'metapub' has no attribute 'PubMedCentralFetcher'
2025-11-05 17:21:02 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for doi 10.1002/glia.24304: module 'metapub' has no attribute 'CrossRef'
2025-11-05 17:21:03 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for pmc PMC3480225: module 'metapub' has no attribute 'PubMedCentralFetcher'
2025-11-05 17:21:05 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for pmc PMC17670: module 'metapub' has no attribute 'PubMedCentralFetcher'
2025-11-05 17:21:06 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for pmc PMC12250119: module 'metapub' has no attribute 'PubMedCentralFetcher'
2025-11-05 17:21:07 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for doi 10.1073/pnas.2413140122: module 'metapub' has no attribute 'CrossRef'
2025-11-05 17:21:09 mib119301s lit_agent.identifiers.validators[48528] WARNING metapub validation failed for doi 10.1038/s41586-023-06502-w: module 'metapub' has no attribute 'CrossRef'
^CTraceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/Users/do12/Documents/GitHub/lit_agent/src/lit_agent/identifiers/validation_demo.py", line 288, in <module>
    report = run_validation_assessment_demo(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/src/lit_agent/identifiers/validation_demo.py", line 100, in run_validation_assessment_demo
    result = extract_identifiers_from_bibliography(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/src/lit_agent/identifiers/api.py", line 59, in extract_identifiers_from_bibliography
    confidence = validator.get_confidence_score(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/src/lit_agent/identifiers/validators.py", line 520, in get_confidence_score
    score = validator.get_confidence_score(identifier_type, value)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/src/lit_agent/identifiers/validators.py", line 451, in get_confidence_score
    if self.validate_identifier(identifier_type, value):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/src/lit_agent/identifiers/validators.py", line 421, in validate_identifier
    article = metapub.PubMedFetcher().article_by_pmid(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/metapub/pubmedfetcher.py", line 155, in _eutils_article_by_pmid
    result = self.qs.efetch({'db': 'pubmed', 'id': pmid})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/eutils/_internal/queryservice.py", line 142, in efetch
    return self._query("/efetch.fcgi", args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/eutils/_internal/queryservice.py", line 299, in _query
    r = requests.post(url, full_args)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/requests/adapters.py", line 644, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 790, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 969, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
               ^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/urllib3/util/ssl_.py", line 480, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/urllib3/util/ssl_.py", line 524, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py", line 1042, in _create
    self.do_handshake()
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py", line 1320, in do_handshake
    self._sslobj.do_handshake()
KeyboardInterrupt
~/Documents/GitHub/lit_agent git:[phase-2-web-scraping]
uv run python -m lit_agent.identifiers.validation_demo
2025-11-05 17:31:14,532 - __main__ - INFO - üîç Extracting URLs from deepsearch bibliography files...
2025-11-05 17:31:14,533 - lit_agent.identifiers.url_extractor - INFO - Extracted 0 URLs from OPENAI_ds_Astrocytes_wmb.md
2025-11-05 17:31:14,534 - lit_agent.identifiers.url_extractor - INFO - Extracted 61 URLs from Astrocytes_patch_seq_ds_perplexity.md
2025-11-05 17:31:14,534 - lit_agent.identifiers.url_extractor - INFO - Extracted 160 URLs from Perplexity_ds_astrocytes_transcriptomics_data.md
2025-11-05 17:31:14,534 - lit_agent.identifiers.url_extractor - INFO - Extracted 197 URLs from Perplexity_ds_astrocytes_markers.md
2025-11-05 17:31:14,535 - lit_agent.identifiers.url_extractor - INFO - Extracted 86 URLs from Perplexity_ds_astrocytes_WMB.md
2025-11-05 17:31:14,535 - lit_agent.identifiers.url_extractor - INFO - Extracted 504 total URLs from 5 files
2025-11-05 17:31:14,535 - lit_agent.identifiers.url_extractor - INFO - Academic URLs: 437, Non-academic: 67
2025-11-05 17:31:14,535 - lit_agent.identifiers.url_extractor - INFO - Removed 62 duplicate URLs
2025-11-05 17:31:14,535 - __main__ - INFO - üìä Sampled 100 URLs from 377 total academic URLs
2025-11-05 17:31:14,535 - __main__ - INFO - üóÇÔ∏è URL extraction stats: 5 files, 377 academic URLs
2025-11-05 17:31:14,535 - __main__ - INFO - üöÄ Starting validation assessment demo with 100 URLs
2025-11-05 17:31:14,535 - __main__ - INFO - Topic validation enabled: True
============================================================
üìä VALIDATION ASSESSMENT DEMO
============================================================
Processing 100 URLs...
Topic validation: ENABLED


17:32:28 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:32:28,961 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:32:29,327 - lit_agent.identifiers.web_scrapers - WARNING - LLM extraction failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:32:29,541 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S0896627317305536
2025-11-05 17:32:30,656 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S2589004223022435
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 6 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 8 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 10 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 12 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 14 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 16 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 18 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 20 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 22 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 24 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 26 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 28 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 30 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 32 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 34 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 44 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 52 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 54 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 56 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 64 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 66 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 68 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 77 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 79 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 87 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 96 0 (offset 0)
2025-11-05 17:32:44,742 - pypdf._reader - WARNING - Ignoring wrong pointing object 104 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 106 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 108 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 110 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 112 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 114 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 119 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 128 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 130 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 132 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 155 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 196 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 223 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 225 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 227 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 229 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 233 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 235 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 237 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 240 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 242 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 245 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 247 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 249 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 286 0 (offset 0)
2025-11-05 17:32:44,743 - pypdf._reader - WARNING - Ignoring wrong pointing object 295 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 333 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 335 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 337 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 361 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 363 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 415 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 427 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 429 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 442 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 451 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 453 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 456 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 475 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 488 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 522 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 527 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 531 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 538 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 547 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 555 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 560 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 562 0 (offset 0)
2025-11-05 17:32:44,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 575 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 599 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 606 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 615 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 617 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 619 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 636 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 638 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 667 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 676 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 678 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 680 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 697 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 713 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 721 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 787 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 789 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 793 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 803 0 (offset 0)
2025-11-05 17:32:44,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 843 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 856 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 882 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 885 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 892 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 897 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 916 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 920 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 936 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 938 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 945 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 957 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 962 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 982 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 986 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 992 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 1004 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 1008 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 1015 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 1017 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 1020 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 1024 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 1027 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 1029 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 1038 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 1040 0 (offset 0)
2025-11-05 17:32:44,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 1042 0 (offset 0)
2025-11-05 17:32:44,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 1057 0 (offset 0)
2025-11-05 17:32:44,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 1059 0 (offset 0)
2025-11-05 17:32:44,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 1065 0 (offset 0)
2025-11-05 17:32:44,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 1103 0 (offset 0)
2025-11-05 17:32:44,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 1131 0 (offset 0)
17:32:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:32:44,772 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:32:44,958 - lit_agent.identifiers.web_scrapers - WARNING - LLM extraction failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:32:48,110 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://aacrjournals.org/cancerres/article/83/7_Supplement/1246/719539/Abstract-1246-Single-cell-profiles-of-multiplexed
2025-11-05 17:32:49,187 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/2073-4409/14/11/758
17:32:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:32:49,655 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:32:49,838 - lit_agent.identifiers.web_scrapers - WARNING - LLM extraction failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:32:50,676 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 404 for https://nyuscholars.nyu.edu/en/publications/longitudinal-scrna-seq-analysis-in-mouse-and-human-informs-optimi
17:32:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:32:52,970 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:32:53,154 - lit_agent.identifiers.web_scrapers - WARNING - LLM extraction failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:32:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:32:55,539 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:32:55,699 - lit_agent.identifiers.web_scrapers - WARNING - LLM extraction failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:32:55,773 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://academic.oup.com/ijnp/article/28/Supplement_2/ii96/8236845
2025-11-05 17:32:56,842 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://academic.oup.com/brain/article/145/1/64/6367770
2025-11-05 17:32:58,119 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/abs/pii/S0301008213000701
17:32:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:32:59,646 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:00,005 - lit_agent.identifiers.web_scrapers - WARNING - LLM extraction failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:03,314 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/1422-0067/25/18/9854
2025-11-05 17:33:04,396 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/1422-0067/22/1/45
2025-11-05 17:33:09,147 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://aacrjournals.org/cancerres/article/83/16_Supplement/A011/728267/Abstract-A011-Single-cell-RNA-sequencing-reveals-a
2025-11-05 17:33:10,250 - lit_agent.identifiers.web_scrapers - WARNING - Request failed for https://singlecell.broadinstitute.org/single_cell/study/SCP795/a-transcriptomic-atlas-of-the-mouse-cerebellum: HTTPSConnectionPool(host='singlecell.broadinstitute.org', port=443): Max retries exceeded with url: /single_cell/study/SCP795/a-transcriptomic-atlas-of-the-mouse-cerebellum (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))
17:33:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:11,666 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:11,859 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 34471129: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:11,859 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 34471129: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:13,640 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:14,698 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 37034735: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:14,698 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 37034735: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:16,135 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:16,602 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 39455606: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:16,602 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 39455606: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:18,084 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:18,274 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 40471378: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:18,274 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 40471378: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:20,997 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:21,177 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 40421586: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:21,178 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 40421586: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:21 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:21,981 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:22,148 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 35587512: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:22,148 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 35587512: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:24,493 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:24,680 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 36915214: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:24,680 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 36915214: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:25 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:25,453 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:25,630 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 32809228: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:25,630 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 32809228: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:27,493 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:27,647 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 40750713: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:27,647 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 40750713: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:29,380 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:29,561 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 37153637: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:29,561 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 37153637: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:31,278 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:31,437 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 35805105: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:31,437 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 35805105: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:34,126 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:34,290 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 34387544: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:34,290 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 34387544: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:36,067 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:36,241 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 32186897: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:36,241 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 32186897: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:38 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:38,907 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:39,100 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 22553043: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:39,100 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 22553043: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:40,845 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:41,041 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 11095732: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:41,041 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 11095732: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:42 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:42,785 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:42,974 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 40650286: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:42,974 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 40650286: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:44,701 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:44,907 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 39761400: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:44,907 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 39761400: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:46,616 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:46,783 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 37674083: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:46,784 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 37674083: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:47,524 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:47,683 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 28355573: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:47,683 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 28355573: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:49,433 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:49,599 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 39300210: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:49,599 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 39300210: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:51,348 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:51,521 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 36744061: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:51,521 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 36744061: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:53,277 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:53,480 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 30529823: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:53,480 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 30529823: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:55,173 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:55,342 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 28355573: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:55,342 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 28355573: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:57,058 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:57,224 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 37552355: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:57,224 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 37552355: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:33:58 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:33:58,952 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:33:59,127 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 26108722: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:33:59,127 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 26108722: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:00 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:00,797 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:00,962 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 7996194: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:00,962 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 7996194: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:01,772 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:01,947 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 28003347: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:01,947 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 28003347: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:03 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:03,679 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:03,850 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 32139688: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:03,850 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 32139688: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:05 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:05,588 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:05,760 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 38548965: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:05,760 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 38548965: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:07 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:07,527 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:07,702 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 34396578: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:07,702 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 34396578: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:10 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:10,432 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:10,603 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 38326616: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:10,603 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 38326616: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:13,464 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:13,643 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 22052455: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:13,643 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 22052455: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:14 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:14,444 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:14,624 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 37697111: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:14,624 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 37697111: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:16,391 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:16,564 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 36291180: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:16,564 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 36291180: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:18,288 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:18,464 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 37449269: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:18,464 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 37449269: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:20,408 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:20,594 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 36285248: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:20,594 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 36285248: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:22,328 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:22,504 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 41082580: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:22,504 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 41082580: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:24,225 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:24,392 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 37451260: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:24,392 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 37451260: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:26,148 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:26,360 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 33627474: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:26,360 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 33627474: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:28 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:28,130 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:28,325 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 40750713: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:28,325 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 40750713: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:30 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:30,074 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:30,247 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 36977817: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:30,247 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 36977817: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:32,001 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:32,165 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 24959138: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:32,165 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 24959138: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:34,900 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:35,081 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 31058383: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:35,081 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 31058383: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:36,861 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:37,031 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 37824652: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:37,031 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 37824652: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:38 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:38,916 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:39,088 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 32426930: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:39,088 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 32426930: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:40,845 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:41,035 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 15155908: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:41,035 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 15155908: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:43,976 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:44,153 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 38405925: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:44,153 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 38405925: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:45 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:45,937 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:46,128 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 32203496: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:46,128 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 32203496: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:47,799 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:48,011 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 20824120: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:48,011 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 20824120: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:51,622 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:51,794 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 31653841: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:51,794 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 31653841: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:53,605 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:53,785 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 33013665: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:53,785 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 33013665: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:34:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:34:55,512 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:34:55,678 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 27698069: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:34:55,678 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 27698069: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:00 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:00,328 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:00,497 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 37383914: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:00,497 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 37383914: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:02 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:02,274 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:02,444 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 21046559: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:02,444 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 21046559: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:04,233 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:04,422 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 37549281: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:04,422 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 37549281: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:07 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:07,154 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:07,326 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 22216277: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:07,326 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 22216277: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:09 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:09,082 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:09,246 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 34572572: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:09,246 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 34572572: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:11,028 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:11,203 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 26485579: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:11,203 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 26485579: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:12 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:12,982 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:13,203 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 28280934: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:13,203 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 28280934: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:14 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:14,935 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:15,226 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 33827819: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:15,226 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 33827819: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:16,858 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:17,038 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 34060113: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:17,038 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 34060113: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:18,802 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:18,980 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 32153350: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:18,980 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 32153350: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:20,764 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:20,947 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 38502590: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:20,947 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 38502590: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:22,717 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:22,898 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 34289357: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:22,898 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 34289357: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
17:35:25 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:35:25,088 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

2025-11-05 17:35:25,264 - lit_agent.identifiers.topic_validator - ERROR - LLM analysis failed for 34289357: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
2025-11-05 17:35:25,264 - lit_agent.identifiers.topic_validator - WARNING - Topic validation failed for 34289357: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: k-svcacc**********************************************************************************************************************************************************pioA. You can find your API key at https://platform.openai.com/account/api-keys.
‚úÖ Processing complete in 0.00 seconds
üìà Success rate: 77.2%
üîç Found 78 identifiers
‚ùå Failed URLs: 23

üìä Identifier Types:
   DOI: 39
   PMID: 5
   PMC: 34

üéØ Topic Validation Summary:
   Papers validated: 65
   Relevant to astrocyte biology: 55
   Irrelevant papers: 10
   Validation errors: 0
   Average confidence: 38.1

üìä Confidence Distribution:
   High confidence (‚â•90%): 76
   Medium confidence (70-89%): 2
   Low confidence (<70%): 0

üìù Generating comprehensive validation report...
2025-11-05 17:35:25,264 - lit_agent.identifiers.reporting - INFO - Generating validation report: validation_demo_20251105_173114
2025-11-05 17:35:25,265 - lit_agent.identifiers.reporting - INFO - Calculating F1 metrics for validation assessment
2025-11-05 17:35:25,268 - lit_agent.identifiers.reporting - INFO - CSV export saved: demo_reports/validation_demo_20251105_173114_papers.csv
2025-11-05 17:35:25,268 - lit_agent.identifiers.reporting - INFO - Reports saved to demo_reports
2025-11-05 17:35:25,268 - lit_agent.identifiers.reporting - INFO - Validation report generated successfully: validation_demo_20251105_173114
‚úÖ Report generated: validation_demo_20251105_173114
üìä Creating visualizations...
2025-11-05 17:35:26,794 - lit_agent.identifiers.visualizations - INFO - Generated 6 visualizations for validation_demo_20251105_173114
‚úÖ Generated 6 visualizations
2025-11-05 17:35:26,809 - lit_agent.identifiers.visualizations - INFO - Interactive HTML report saved: demo_reports/validation_demo_20251105_173114_interactive_report.html
üåê Interactive HTML report: demo_reports/validation_demo_20251105_173114_interactive_report.html
============================================================
üîç VALIDATION ASSESSMENT INSIGHTS
============================================================
üìà Performance Metrics:
   Overall success rate: 77.0%
   Processing efficiency: 0.00s per batch
   Total identifiers extracted: 78

üéØ Topic Validation Insights:
   Papers relevant to astrocyte biology: 55
   Papers likely irrelevant: 10
   Average topic confidence: 45.0
   Most common keywords: astrocyte, astrocytes, glia, glial, reactive astrocytes

üí° RECOMMENDATIONS:
   1. ü§ñ Low average topic validation confidence (45.0). Consider adjusting LLM prompts or model parameters.

üìã Manual Review Suggestions:
   13 papers need manual review
   35 relevant papers have low confidence scores
   10 papers identified as likely irrelevant

============================================================
üéØ PAUSE POINT ASSESSMENT
============================================================
üìä Validation Quality Score: 64.8/100
   Based on: relevance rate (70.5%), confidence (45.0), success rate (77.0%)

‚ùå ASSESSMENT: Validation quality needs IMPROVEMENT
   ‚Üí Address critical issues identified in recommendations
   ‚Üí Consider manual review of all papers before proceeding

üìÅ Complete reports saved to: /Users/do12/Documents/GitHub/lit_agent/demo_reports
============================================================

üéâ Demo completed successfully!
Check the 'demo_reports' directory for generated files.
~/Documents/GitHub/lit_agent git:[phase-2-web-scraping]
uv run python -m lit_agent.identifiers.validation_demo
2025-11-05 17:53:33,255 - __main__ - INFO - üîç Extracting URLs from deepsearch bibliography files...
2025-11-05 17:53:33,256 - lit_agent.identifiers.url_extractor - INFO - Extracted 0 URLs from OPENAI_ds_Astrocytes_wmb.md
2025-11-05 17:53:33,256 - lit_agent.identifiers.url_extractor - INFO - Extracted 61 URLs from Astrocytes_patch_seq_ds_perplexity.md
2025-11-05 17:53:33,257 - lit_agent.identifiers.url_extractor - INFO - Extracted 160 URLs from Perplexity_ds_astrocytes_transcriptomics_data.md
2025-11-05 17:53:33,257 - lit_agent.identifiers.url_extractor - INFO - Extracted 197 URLs from Perplexity_ds_astrocytes_markers.md
2025-11-05 17:53:33,257 - lit_agent.identifiers.url_extractor - INFO - Extracted 86 URLs from Perplexity_ds_astrocytes_WMB.md
2025-11-05 17:53:33,257 - lit_agent.identifiers.url_extractor - INFO - Extracted 504 total URLs from 5 files
2025-11-05 17:53:33,257 - lit_agent.identifiers.url_extractor - INFO - Academic URLs: 437, Non-academic: 67
2025-11-05 17:53:33,257 - lit_agent.identifiers.url_extractor - INFO - Removed 62 duplicate URLs
2025-11-05 17:53:33,257 - __main__ - INFO - üìä Sampled 100 URLs from 377 total academic URLs
2025-11-05 17:53:33,257 - __main__ - INFO - üóÇÔ∏è URL extraction stats: 5 files, 377 academic URLs
2025-11-05 17:53:33,257 - __main__ - INFO - üöÄ Starting validation assessment demo with 100 URLs
2025-11-05 17:53:33,257 - __main__ - INFO - Topic validation enabled: True
============================================================
üìä VALIDATION ASSESSMENT DEMO
============================================================
Processing 100 URLs...
Topic validation: ENABLED

17:54:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:54:47,633 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:54:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:54:51,047 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-05 17:54:51,245 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S0896627317305536
2025-11-05 17:54:52,363 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S2589004223022435
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 6 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 8 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 10 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 12 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 14 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 16 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 18 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 20 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 22 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 24 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 26 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 28 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 30 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 32 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 34 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 44 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 52 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 54 0 (offset 0)
2025-11-05 17:55:13,967 - pypdf._reader - WARNING - Ignoring wrong pointing object 56 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 64 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 66 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 68 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 77 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 79 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 87 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 96 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 104 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 106 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 108 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 110 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 112 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 114 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 119 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 128 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 130 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 132 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 155 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 196 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 223 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 225 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 227 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 229 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 233 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 235 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 237 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 240 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 242 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 245 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 247 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 249 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 286 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 295 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 333 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 335 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 337 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 361 0 (offset 0)
2025-11-05 17:55:13,968 - pypdf._reader - WARNING - Ignoring wrong pointing object 363 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 415 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 427 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 429 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 442 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 451 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 453 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 456 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 475 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 488 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 522 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 527 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 531 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 538 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 547 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 555 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 560 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 562 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 575 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 599 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 606 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 615 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 617 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 619 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 636 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 638 0 (offset 0)
2025-11-05 17:55:13,969 - pypdf._reader - WARNING - Ignoring wrong pointing object 667 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 676 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 678 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 680 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 697 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 713 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 721 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 787 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 789 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 793 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 803 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 843 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 856 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 882 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 885 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 892 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 897 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 916 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 920 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 936 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 938 0 (offset 0)
2025-11-05 17:55:13,970 - pypdf._reader - WARNING - Ignoring wrong pointing object 945 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 957 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 962 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 982 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 986 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 992 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1004 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1008 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1015 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1017 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1020 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1024 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1027 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1029 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1038 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1040 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1042 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1057 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1059 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1065 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1103 0 (offset 0)
2025-11-05 17:55:13,971 - pypdf._reader - WARNING - Ignoring wrong pointing object 1131 0 (offset 0)
17:55:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:55:13,996 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:55:15 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:15,556 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:18,184 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://aacrjournals.org/cancerres/article/83/7_Supplement/1246/719539/Abstract-1246-Single-cell-profiles-of-multiplexed
2025-11-05 17:55:19,273 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/2073-4409/14/11/758
17:55:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:55:19,726 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:55:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:21,135 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:21,586 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 404 for https://nyuscholars.nyu.edu/en/publications/longitudinal-scrna-seq-analysis-in-mouse-and-human-informs-optimi
17:55:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:55:22,389 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:55:23 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:23,722 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:55:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:55:24,924 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:55:26 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:26,847 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:26,949 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://academic.oup.com/ijnp/article/28/Supplement_2/ii96/8236845
2025-11-05 17:55:28,035 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://academic.oup.com/brain/article/145/1/64/6367770
2025-11-05 17:55:29,249 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/abs/pii/S0301008213000701
17:55:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:55:29,499 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:55:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:30,298 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:33,375 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/1422-0067/25/18/9854
2025-11-05 17:55:34,457 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/1422-0067/22/1/45
2025-11-05 17:55:39,164 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://aacrjournals.org/cancerres/article/83/16_Supplement/A011/728267/Abstract-A011-Single-cell-RNA-sequencing-reveals-a
2025-11-05 17:55:40,285 - lit_agent.identifiers.web_scrapers - WARNING - Request failed for https://singlecell.broadinstitute.org/single_cell/study/SCP795/a-transcriptomic-atlas-of-the-mouse-cerebellum: HTTPSConnectionPool(host='singlecell.broadinstitute.org', port=443): Max retries exceeded with url: /single_cell/study/SCP795/a-transcriptomic-atlas-of-the-mouse-cerebellum (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))
17:55:41 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:55:41,753 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:55:42 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:42,946 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:55:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:55:44,954 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:55:47 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:47,961 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:55:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:55:49,969 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:55:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:54,224 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:55:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:55:56,232 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:55:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:55:57,821 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:00 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:00,226 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:02,299 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:04,305 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:06,404 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:08,411 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:09,485 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:11,490 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:12 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:12,644 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:14 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:14,649 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:16 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:16,534 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:18,542 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:20,016 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:22,024 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:23 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:23,084 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:25 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:25,503 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:27 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:27,500 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:29,507 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:30,768 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:33 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:33,204 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:34,476 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:36,484 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:37,652 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:39,659 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:41,531 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:43,536 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:45,057 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:47,075 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:50,024 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:52,032 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:53 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:53,219 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:55,228 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:56 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:56,374 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:56:58 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:56:58,381 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:56:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:56:59,929 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:01,935 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:03,799 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:07 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:07,279 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:09,588 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:11,594 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:13 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:13,110 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:15 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:15,112 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:19 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:19,724 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:21 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:21,731 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:22 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:22,693 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:24,697 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:25 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:25,970 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:27,974 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:29,349 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:31,354 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:32,830 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:35 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:35,204 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:37,241 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:39,677 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:41,125 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:43,131 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:44,622 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:46,630 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:48,390 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:50 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:50,393 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:52 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:52,181 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:54 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:54,189 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:55 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:55,560 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:57:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:57:57,567 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:57:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:57:59,041 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:01,045 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:02,626 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:04,631 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:07 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:07,040 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:10 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:10,565 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:12 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:12,870 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:14 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:14,875 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:16 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:16,451 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:18,890 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:20,969 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:22,975 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:24 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:24,642 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:26,649 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:28 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:28,023 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:30 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:30,029 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:31 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:31,456 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:33 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:33,895 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:35 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:35,460 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:37 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:37,467 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:39 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:39,543 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:41 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:41,546 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:42 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:42,665 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:46,064 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:47 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:47,478 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:49,485 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:51,137 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:53,141 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:58:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:58:54,854 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:58:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:58:59,203 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:00 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:00,954 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:02 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:02,959 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:04 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:04,772 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:06 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:06,776 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:08 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:08,011 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:10 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:10,425 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:11 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:11,739 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:13,743 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:14,961 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:16,968 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:18 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:18,916 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:20,919 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:23 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:23,727 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:25 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:25,733 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:27 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:27,079 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:29,084 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:33 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:33,089 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:35 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:35,095 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:37,367 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:39,370 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:40 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:40,931 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:42 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:42,937 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:44,797 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:46,802 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:47 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:47,700 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:49,707 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:51,272 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
17:59:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 17:59:55,875 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
17:59:56 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 17:59:56,905 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
18:00:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-05 18:00:01,618 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
18:00:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-05 18:00:02,845 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
‚úÖ Processing complete in 0.00 seconds
üìà Success rate: 82.1%
üîç Found 87 identifiers
‚ùå Failed URLs: 19

üìä Identifier Types:
   DOI: 43
   PMID: 7
   PMC: 37

üéØ Topic Validation Summary:
   Papers validated: 73
   Relevant to astrocyte biology: 56
   Irrelevant papers: 17
   Validation errors: 0
   Average confidence: 79.2

üìä Confidence Distribution:
   High confidence (‚â•90%): 76
   Medium confidence (70-89%): 11
   Low confidence (<70%): 0

üìù Generating comprehensive validation report...
2025-11-05 18:00:05,181 - lit_agent.identifiers.reporting - INFO - Generating validation report: validation_demo_20251105_175333
2025-11-05 18:00:05,182 - lit_agent.identifiers.reporting - INFO - Calculating F1 metrics for validation assessment
2025-11-05 18:00:05,193 - lit_agent.identifiers.reporting - INFO - CSV export saved: demo_reports/validation_demo_20251105_175333_papers.csv
2025-11-05 18:00:05,193 - lit_agent.identifiers.reporting - INFO - Reports saved to demo_reports
2025-11-05 18:00:05,193 - lit_agent.identifiers.reporting - INFO - Validation report generated successfully: validation_demo_20251105_175333
‚úÖ Report generated: validation_demo_20251105_175333
üìä Creating visualizations...
2025-11-05 18:00:06,571 - lit_agent.identifiers.visualizations - INFO - Generated 6 visualizations for validation_demo_20251105_175333
‚úÖ Generated 6 visualizations
2025-11-05 18:00:06,578 - lit_agent.identifiers.visualizations - INFO - Interactive HTML report saved: demo_reports/validation_demo_20251105_175333_interactive_report.html
üåê Interactive HTML report: demo_reports/validation_demo_20251105_175333_interactive_report.html
============================================================
üîç VALIDATION ASSESSMENT INSIGHTS
============================================================
üìà Performance Metrics:
   Overall success rate: 81.0%
   Processing efficiency: 0.00s per batch
   Total identifiers extracted: 87

üéØ Topic Validation Insights:
   Papers relevant to astrocyte biology: 56
   Papers likely irrelevant: 17
   Average topic confidence: 93.3
   Most common keywords: astrocyte, glial, calcium signaling, glial cells, gfap

üí° RECOMMENDATIONS:
   1. ‚úÖ Validation performance looks good! Consider proceeding with manual spot-checking of medium confidence papers.

üìã Manual Review Suggestions:
   14 papers need manual review
   17 papers identified as likely irrelevant

============================================================
üéØ PAUSE POINT ASSESSMENT
============================================================
üìä Validation Quality Score: 78.0/100
   Based on: relevance rate (64.4%), confidence (93.3), success rate (81.0%)

‚ö†Ô∏è ASSESSMENT: Validation quality is GOOD but has room for improvement
   ‚Üí Review recommendations above for optimization
   ‚Üí Consider manual review of medium-confidence papers

üìÅ Complete reports saved to: /Users/do12/Documents/GitHub/lit_agent/demo_reports
============================================================

üéâ Demo completed successfully!
Check the 'demo_reports' directory for generated files.
~/Documents/GitHub/lit_agent git:[phase-2-web-scraping]
uv run ruff format
1 file reformatted, 24 files left unchanged
~/Documents/GitHub/lit_agent git:[phase-2-web-scraping]
uv run ruff format
25 files left unchanged
~/Documents/GitHub/lit_agent git:[phase-2-web-scraping]
uv run ruff check . --fix
Found 2 errors (2 fixed, 0 remaining).
~/Documents/GitHub/lit_agent git:[phase-2-web-scraping]
uv run ruff check . --fix
All checks passed!
~/Documents/GitHub/lit_agent git:[phase-2-web-scraping]
uv run python -m lit_agent.identifiers.validation_demo
2025-11-06 12:55:28,904 - __main__ - INFO - üîç Extracting URLs from deepsearch bibliography files...
2025-11-06 12:55:28,905 - lit_agent.identifiers.url_extractor - INFO - Extracted 0 URLs from OPENAI_ds_Astrocytes_wmb.md
2025-11-06 12:55:28,905 - lit_agent.identifiers.url_extractor - INFO - Extracted 61 URLs from Astrocytes_patch_seq_ds_perplexity.md
2025-11-06 12:55:28,905 - lit_agent.identifiers.url_extractor - INFO - Extracted 160 URLs from Perplexity_ds_astrocytes_transcriptomics_data.md
2025-11-06 12:55:28,906 - lit_agent.identifiers.url_extractor - INFO - Extracted 197 URLs from Perplexity_ds_astrocytes_markers.md
2025-11-06 12:55:28,906 - lit_agent.identifiers.url_extractor - INFO - Extracted 86 URLs from Perplexity_ds_astrocytes_WMB.md
2025-11-06 12:55:28,906 - lit_agent.identifiers.url_extractor - INFO - Extracted 504 total URLs from 5 files
2025-11-06 12:55:28,906 - lit_agent.identifiers.url_extractor - INFO - Academic URLs: 437, Non-academic: 67
2025-11-06 12:55:28,906 - lit_agent.identifiers.url_extractor - INFO - Removed 62 duplicate URLs
2025-11-06 12:55:28,906 - __main__ - INFO - üìä Using all 377 academic URLs from deepsearch files
2025-11-06 12:55:28,906 - __main__ - INFO - üóÇÔ∏è URL extraction stats: 5 files, 377 academic URLs
2025-11-06 12:55:28,906 - __main__ - INFO - üöÄ Starting validation assessment demo with 377 URLs
2025-11-06 12:55:28,906 - __main__ - INFO - Topic validation enabled: True
============================================================
üìä VALIDATION ASSESSMENT DEMO
============================================================
Processing 377 URLs...
Topic validation: ENABLED

13:03:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:03:27,064 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:03:28 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:03:28,444 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:03:28 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:03:28,791 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:03:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:03:30,398 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:03:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:03:32,354 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:03:33 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:03:33,800 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:03:35 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:03:35,916 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:03:36 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:03:36,808 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:03:38 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:03:38,673 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:03:39 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:03:39,973 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:03:42 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:03:42,644 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:03:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:03:44,161 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:03:45 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:03:45,815 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:03:46 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:03:46,721 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:03:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:03:49,651 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:03:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:03:50,864 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:03:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:03:52,177 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:03:53 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:03:53,159 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-06 13:03:53,498 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S0092867425010281
13:03:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:03:57,718 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:03:58 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:03:58,387 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-06 13:04:08,608 - lit_agent.identifiers.web_scrapers - WARNING - Request failed for https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE114000: HTTPSConnectionPool(host='www.ncbi.nlm.nih.gov', port=443): Read timed out. (read timeout=10)
2025-11-06 13:04:20,320 - lit_agent.identifiers.web_scrapers - WARNING - Request failed for https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE246717: HTTPSConnectionPool(host='www.ncbi.nlm.nih.gov', port=443): Read timed out. (read timeout=10)
2025-11-06 13:04:30,562 - lit_agent.identifiers.web_scrapers - WARNING - Request failed for https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE73721: HTTPSConnectionPool(host='www.ncbi.nlm.nih.gov', port=443): Read timed out. (read timeout=10)
2025-11-06 13:04:32,689 - lit_agent.identifiers.web_scrapers - WARNING - Request failed for https://singlecell.broadinstitute.org/single_cell/study/SCP795/a-transcriptomic-atlas-of-the-mouse-cerebellum: HTTPSConnectionPool(host='singlecell.broadinstitute.org', port=443): Max retries exceeded with url: /single_cell/study/SCP795/a-transcriptomic-atlas-of-the-mouse-cerebellum (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))
2025-11-06 13:04:32,900 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 406 for https://elifesciences.org/articles/92046
2025-11-06 13:04:34,166 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://rupress.org/jem/article/218/8/e20210040/212391/Single-cell-analysis-of-the-cellular-heterogeneity
2025-11-06 13:04:45,415 - lit_agent.identifiers.web_scrapers - WARNING - Request failed for https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE202627: HTTPSConnectionPool(host='www.ncbi.nlm.nih.gov', port=443): Read timed out. (read timeout=10)
2025-11-06 13:04:53,150 - lit_agent.identifiers.web_scrapers - WARNING - Request failed for https://portals.broadinstitute.org/single_cell/study/a-molecular-census-of-arcuate-hypothalamus-and-median-eminence-cell-types: HTTPSConnectionPool(host='singlecell.broadinstitute.org', port=443): Max retries exceeded with url: /single_cell/study/a-molecular-census-of-arcuate-hypothalamus-and-median-eminence-cell-types (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))
2025-11-06 13:04:53,294 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://academic.oup.com/proteincell/article/14/8/603/7049315
2025-11-06 13:05:05,172 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://academic.oup.com/nar/article/52/D1/D1033/7334093
2025-11-06 13:05:06,719 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 404 for https://nyuscholars.nyu.edu/en/publications/longitudinal-scrna-seq-analysis-in-mouse-and-human-informs-optimi
2025-11-06 13:05:09,302 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S2589004223022435
2025-11-06 13:05:13,733 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S2211124722000444
2025-11-06 13:05:15,089 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S0896627317305536
2025-11-06 13:05:17,861 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S2211124721009384
2025-11-06 13:05:20,269 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://rupress.org/jcb/article/222/11/e202303138/276267/Catenin-controls-astrocyte-morphogenesis-via-layer
2025-11-06 13:05:23,540 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/2073-4409/10/1/72
2025-11-06 13:05:24,657 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://rupress.org/jem/article/216/1/71/42439/Astrocytes-and-microglia-Models-and-toolsThe
2025-11-06 13:05:26,049 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.biocompare.com/Editorial-Articles/587544-A-Guide-to-Astrocyte-Markers/
2025-11-06 13:05:27,377 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.biocompare.com/Editorial-Articles/595024-A-Guide-to-Glial-Cell-Markers/
2025-11-06 13:05:28,496 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://academic.oup.com/brain/article/145/1/64/6367770
2025-11-06 13:05:29,834 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S2213671123002369
2025-11-06 13:05:32,178 - bs4.dammit - WARNING - Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.
13:05:33 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:05:33,768 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:05:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:05:34,545 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-06 13:05:36,910 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://academic.oup.com/neuro-oncology/article/24/Supplement_7/vii300/6826893
2025-11-06 13:05:38,012 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://academic.oup.com/stmcls/article/23/10/1443-1452/6399855
2025-11-06 13:05:39,147 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://academic.oup.com/nar/article/39/4/e24/1005955
2025-11-06 13:05:40,246 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/1422-0067/22/1/45
2025-11-06 13:05:41,355 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/2073-4409/12/17/2172/pdf?version=1693367665
2025-11-06 13:05:43,823 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/2218-273X/13/4/692
2025-11-06 13:05:44,979 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://aacrjournals.org/cancerres/article/84/17_Supplement/B006/747222/Abstract-B006-An-integrated-single-cell-RNA-seq
2025-11-06 13:05:46,087 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://aacrjournals.org/cancerres/article/84/6_Supplement/2026/738845/Abstract-2026-Single-cell-RNA-sequencing-analysis
2025-11-06 13:05:47,189 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://aacrjournals.org/cancerres/article/84/6_Supplement/6249/740515/Abstract-6249-Single-cell-RNA-sequencing
2025-11-06 13:05:48,315 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://aacrjournals.org/cancerres/article/83/16_Supplement/A011/728267/Abstract-A011-Single-cell-RNA-sequencing-reveals-a
2025-11-06 13:05:49,426 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://aacrjournals.org/cancerres/article/84/6_Supplement/6831/738149/Abstract-6831-Single-cell-based-epigenetic-and
2025-11-06 13:05:50,537 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://aacrjournals.org/cancerres/article/84/17_Supplement_2/IA-02/747708/Abstract-IA-02-The-tumor-reactive-CD8-T-cell
2025-11-06 13:05:51,640 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://aacrjournals.org/cancerres/article/83/7_Supplement/1246/719539/Abstract-1246-Single-cell-profiles-of-multiplexed
2025-11-06 13:05:52,750 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://aacrjournals.org/cancerres/article/84/6_Supplement/2662/738262/Abstract-2662-Deciphering-the-cellular-and
2025-11-06 13:05:53,883 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/2218-273X/13/4/692/pdf?version=1682042632
2025-11-06 13:05:55,080 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4938462
2025-11-06 13:05:55,378 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for PDF https://www.science.org/cms/asset/24391b1d-9639-46e3-b8dc-a661a7763504/pap.pdf
2025-11-06 13:05:56,365 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S0197458024000915
2025-11-06 13:05:57,535 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://iovs.arvojournals.org/article.aspx?articleid=2182305
2025-11-06 13:05:58,878 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/abs/pii/S0006899301031249
2025-11-06 13:06:00,010 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://academic.oup.com/ijnp/article/28/Supplement_2/ii96/8236845
2025-11-06 13:06:02,839 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/2073-4409/11/7/1139/pdf
2025-11-06 13:06:04,043 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S0301008218301631
2025-11-06 13:06:05,341 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/abs/pii/S0301008213000701
2025-11-06 13:06:06,546 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/2218-273X/11/9/1361/pdf
2025-11-06 13:06:07,654 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/2073-4409/13/11/921
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 6 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 8 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 10 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 12 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 14 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 16 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 18 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 20 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 22 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 24 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 26 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 28 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 30 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 32 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 34 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 44 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 52 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 54 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 56 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 64 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 66 0 (offset 0)
2025-11-06 13:06:13,744 - pypdf._reader - WARNING - Ignoring wrong pointing object 68 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 77 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 79 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 87 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 96 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 104 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 106 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 108 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 110 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 112 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 114 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 119 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 128 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 130 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 132 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 155 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 196 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 223 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 225 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 227 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 229 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 233 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 235 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 237 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 240 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 242 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 245 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 247 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 249 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 286 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 295 0 (offset 0)
2025-11-06 13:06:13,745 - pypdf._reader - WARNING - Ignoring wrong pointing object 333 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 335 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 337 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 361 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 363 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 415 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 427 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 429 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 442 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 451 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 453 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 456 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 475 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 488 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 522 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 527 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 531 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 538 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 547 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 555 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 560 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 562 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 575 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 599 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 606 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 615 0 (offset 0)
2025-11-06 13:06:13,746 - pypdf._reader - WARNING - Ignoring wrong pointing object 617 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 619 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 636 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 638 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 667 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 676 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 678 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 680 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 697 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 713 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 721 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 787 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 789 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 793 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 803 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 843 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 856 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 882 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 885 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 892 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 897 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 916 0 (offset 0)
2025-11-06 13:06:13,747 - pypdf._reader - WARNING - Ignoring wrong pointing object 920 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 936 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 938 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 945 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 957 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 962 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 982 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 986 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 992 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1004 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1008 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1015 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1017 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1020 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1024 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1027 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1029 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1038 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1040 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1042 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1057 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1059 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1065 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1103 0 (offset 0)
2025-11-06 13:06:13,748 - pypdf._reader - WARNING - Ignoring wrong pointing object 1131 0 (offset 0)
13:06:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:06:13,773 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:06:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:06:14,408 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-06 13:06:14,709 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S2666354625000067
2025-11-06 13:06:16,054 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/abs/pii/S1568163722002173
2025-11-06 13:06:17,169 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/1422-0067/25/18/9854
2025-11-06 13:06:18,284 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/2073-4409/14/11/758
13:06:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:06:19,345 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:06:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:06:21,474 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-06 13:06:21,690 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S009286741830789X
2025-11-06 13:06:22,913 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/abs/pii/S0955067415000137
2025-11-06 13:06:24,104 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 202 for https://joe.bioscientifica.com/view/journals/joe/265/3/JOE-24-0318.xml
2025-11-06 13:06:26,070 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/science/article/pii/S0168010224000981
2025-11-06 13:06:27,219 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://academic.oup.com/cercor/article/27/3/2195/3056310
2025-11-06 13:06:28,537 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.sciencedirect.com/topics/biochemistry-genetics-and-molecular-biology/olfactory-marker-protein
2025-11-06 13:06:29,685 - lit_agent.identifiers.web_scrapers - WARNING - HTTP 403 for https://www.mdpi.com/1422-0067/23/5/2646/pdf
13:06:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:06:31,370 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:06:33 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:06:33,233 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:06:35 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:06:35,240 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:06:36 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:06:36,404 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:06:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:06:39,995 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:06:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:06:41,425 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:06:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:06:43,933 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:06:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:06:45,112 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:06:48 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:06:48,977 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:06:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:06:50,908 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:06:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:06:52,914 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:06:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:06:54,724 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:06:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:06:57,274 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:06:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:06:59,216 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:01,219 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:02,517 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:04,525 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:05 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:05,680 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:09 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:09,229 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:10,954 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:12 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:12,957 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:14,623 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:16,628 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:18 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:18,014 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:20,021 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:21,359 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:23 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:23,362 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:24 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:24,370 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:26,377 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:28 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:28,015 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:30 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:30,023 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:31 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:31,396 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:33 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:33,403 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:34,699 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:36,705 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:38,062 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:45 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:45,706 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:47 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:47,119 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:49,127 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:50,556 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:52,562 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:53 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:53,617 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:07:58 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:07:58,392 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:07:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:07:59,633 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:01,641 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:03,044 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:05 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:05,052 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:06,727 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:08,731 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:10,144 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:12 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:12,750 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:14,610 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:16,614 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:17 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:17,887 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:19,893 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:21,472 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:24,020 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:25 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:25,362 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:31,037 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:32,417 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:38 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:38,445 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:39 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:39,728 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:41 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:41,734 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:43 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:43,085 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:45 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:45,089 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:46 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:46,249 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:48 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:48,263 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:49 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:49,590 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:51,596 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:55 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:55,094 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:08:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:08:57,749 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:08:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:08:59,054 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:01,061 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:02,533 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:04,541 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:05 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:05,754 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:07 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:07,760 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:09,090 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:11,094 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:13 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:13,081 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:15 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:15,089 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:16 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:16,255 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:18,262 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:19 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:19,327 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:21 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:21,334 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:22 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:22,605 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:26,230 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:28 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:28,032 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:30 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:30,036 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:31 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:31,514 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:35 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:35,397 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:37,759 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:40,329 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:41,626 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:43,633 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:44,962 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:47,423 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:48,547 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:50 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:50,555 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:52 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:52,197 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:54 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:54,205 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:55 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:55,764 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:09:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:09:57,769 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:09:58 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:09:58,998 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:01,605 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:03,564 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:05 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:05,568 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:06,737 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:08,742 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:09,662 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:12 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:12,173 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:13 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:13,704 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:15 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:15,712 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:17 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:17,209 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:19,216 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:20,673 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:24,232 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:25 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:25,380 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:28 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:28,655 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:29,890 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:31,894 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:33 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:33,366 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:35 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:35,371 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:37,154 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:39,161 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:40 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:40,327 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:42 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:42,333 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:43 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:43,561 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:45 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:45,569 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:46 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:46,836 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:47,434 - lit_agent.identifiers.validators - WARNING - NCBI API returned status 429
13:10:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:49,427 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:50,914 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:53,650 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:54,527 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:56,530 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:10:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:10:57,837 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:10:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:10:59,840 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:01 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:01,114 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:03 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:03,121 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:04 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:04,465 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:06 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:06,471 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:07 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:07,676 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:09 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:09,682 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:10,740 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:13,427 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:14,822 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:16,828 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:18 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:18,116 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:20,124 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:21,082 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:25 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:25,897 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:30,015 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:32,022 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:32,937 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:34,942 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:36 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:36,237 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:39,851 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:41,568 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:43,572 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:44,960 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:46,969 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:48,647 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:50 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:50,654 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:51,935 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:54 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:54,509 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:55 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:55,883 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:11:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:11:57,890 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:11:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:11:59,382 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:01,387 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:03,476 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:05 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:05,480 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:06,618 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:08,622 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:10,326 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:12 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:12,334 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:14,133 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:16,141 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:18 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:18,113 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:20,118 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:21,398 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:23 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:23,406 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:24 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:24,872 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:26,876 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:28 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:28,844 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:32,377 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:34,056 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:36,062 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:37,509 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:39,515 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:40 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:40,760 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:42 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:42,768 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:44,239 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:46,776 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:48,229 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:50 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:50,233 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:51,537 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:12:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:12:55,070 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:12:56 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:12:56,635 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:00 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:00,153 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:01 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:01,335 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:03 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:03,342 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:04 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:04,753 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:08,312 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:09,526 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:11,532 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:12 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:12,978 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:14 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:14,986 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:16 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:16,169 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:18,177 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:19 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:19,653 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:21 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:21,658 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:22 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:22,842 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:26,503 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:27 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:27,653 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:29,661 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:31 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:31,052 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:33 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:33,055 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:34,410 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:36,418 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:38,096 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:40,104 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:42 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:42,029 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:44,032 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:45,367 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:48 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:48,958 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:51,100 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:53,108 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:54,124 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:56,132 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:13:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:13:57,242 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:13:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:13:59,247 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:00 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:00,522 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:02 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:02,526 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:04 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:04,002 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:06 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:06,010 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:07 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:07,384 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:10 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:10,066 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:11 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:11,914 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:13,918 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:15 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:15,268 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:17 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:17,270 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:18 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:18,546 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:20,553 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:22 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:22,066 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:24,072 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:25 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:25,726 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:28 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:28,276 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:29,298 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:31,306 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:32,600 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:36,076 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:37,898 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:39,904 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:41,483 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:43,490 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:44,807 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:49,414 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:51,316 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:53,873 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:55 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:55,358 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:14:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:14:57,365 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:14:58 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:14:58,364 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:00 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:00,375 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:01 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:01,657 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:03 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:03,666 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:05 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:05,120 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:07 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:07,684 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:09,129 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:11,135 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:12 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:12,886 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:16,461 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:17 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:17,456 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:19,462 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:20,444 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:22,461 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:24 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:24,372 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:28 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:28,969 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:30,157 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:32,165 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:33 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:33,621 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:37 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:37,238 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:38,794 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:40,800 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:42 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:42,184 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:45 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:45,773 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:47 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:47,023 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:49,028 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:51,136 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:55,716 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:15:56 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:15:56,927 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:15:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:15:59,492 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:03,815 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:16:05 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:16:05,822 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:07 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:07,288 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:16:09 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:16:09,852 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:11 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:11,718 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:16:15 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:16:15,163 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:17 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:17,154 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:16:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:16:22,866 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:24 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:24,445 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:16:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:16:27,127 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:28 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:28,289 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:16:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:16:32,939 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:34,391 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:16:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:16:36,401 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:37,606 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:16:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:16:39,612 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:42 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:42,113 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:16:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:16:44,118 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:45,288 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:16:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:16:47,293 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:48,975 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:16:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:16:51,433 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:52 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:52,869 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:16:54 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:16:54,875 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:16:56 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:16:56,259 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:17:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:17:01,063 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:17:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:17:02,957 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:17:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:17:04,966 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:17:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:17:06,494 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:17:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:17:08,501 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:17:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:17:09,966 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:17:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:17:11,974 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:17:13 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:17:13,449 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:17:15 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:17:15,452 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:17:16 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:17:16,982 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:17:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:17:18,990 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:17:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:17:21,127 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:17:23 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:17:23,132 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:17:24 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:17:24,460 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:17:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:17:26,465 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:17:27 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:17:27,746 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:17:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:17:29,754 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:18:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:18:30,459 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:18:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:18:32,467 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:18:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:18:34,353 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:18:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:18:36,359 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:18:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:18:38,077 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:18:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:18:40,081 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:18:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:18:41,525 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:18:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:18:44,045 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:18:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:18:45,314 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:18:48 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:18:48,848 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:18:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:18:50,225 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:18:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:18:52,233 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:18:53 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:18:53,610 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:18:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:18:55,617 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:18:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:18:57,097 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:18:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:18:59,101 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:19:00 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:19:00,376 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:19:02 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:19:02,384 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:19:04 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:19:04,061 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:19:06 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:19:06,528 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:19:07 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:19:07,950 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:19:09 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:19:09,958 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:19:11 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:19:11,948 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:19:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:19:13,956 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:19:15 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:19:15,427 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:19:17 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:19:17,434 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:19:18 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:19:18,823 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:19:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:19:20,830 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:19:22 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:19:22,292 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:19:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:19:24,851 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:19:26 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:19:26,899 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:19:28 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:19:28,907 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:19:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:19:30,480 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:19:33 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:19:33,996 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:19:35 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:19:35,500 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:19:37 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:19:37,507 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:19:39 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:19:39,036 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:19:41 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:19:41,655 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:19:42 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:19:42,974 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:19:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:19:44,981 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:20:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:20:20,502 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:20:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:20:22,511 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:20:24 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:20:24,243 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:20:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:20:26,250 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:20:27 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:20:27,179 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:20:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:20:29,187 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:20:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:20:30,519 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:20:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:20:32,526 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:20:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:20:34,303 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:20:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:20:36,770 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:20:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:20:38,272 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:20:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:20:40,277 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:20:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:20:41,959 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:20:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:20:44,512 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:20:46 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:20:46,057 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:20:48 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:20:48,263 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:20:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:20:50,011 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:20:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:20:52,017 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:20:53 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:20:53,248 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:20:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:20:55,255 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:20:56 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:20:56,806 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:21:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:21:08,440 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:21:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:21:09,856 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:21:15 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:21:15,410 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:21:16 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:21:16,880 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:21:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:21:19,304 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:21:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:21:20,608 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:21:28 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:21:28,294 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:21:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:21:29,402 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:21:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:21:31,408 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:21:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:21:32,999 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:21:35 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:21:35,006 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:21:36 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:21:36,437 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-06 13:21:38,038 - lit_agent.identifiers.validators - WARNING - NCBI API returned status 429
13:21:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:21:40,055 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:21:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:21:41,299 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:21:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:21:47,849 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:21:49 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:21:49,804 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:21:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:21:51,810 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:21:52 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:21:52,833 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:21:54 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:21:54,841 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:21:56 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:21:56,817 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:21:58 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:21:58,824 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:00 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:00,225 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:02 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:02,228 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:03,780 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:06 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:06,321 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:07 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:07,462 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:09 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:09,466 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:10,598 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:12 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:12,602 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:13 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:13,577 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:16,089 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:17 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:17,019 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:19,027 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:20,366 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:22,882 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:23 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:23,851 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:25 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:25,855 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:26 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:26,709 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:28 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:28,716 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:30,242 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:32,245 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:33 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:33,575 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:35 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:35,582 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:36 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:36,827 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:38 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:38,835 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:40 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:40,366 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:42 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:42,374 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:43 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:43,190 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:46,772 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:47 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:47,697 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:49,700 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:50,813 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:52,819 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:54,162 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:56,639 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:22:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:22:57,434 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:22:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:22:59,442 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:00 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:00,240 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:23:02 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:23:02,246 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:03,477 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:23:07 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:23:07,056 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:08 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:08,292 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:23:10 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:23:10,299 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:11 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:11,102 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:23:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:23:13,582 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:14,545 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:23:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:23:19,170 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:20,329 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:23:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:23:22,902 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:23 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:23,928 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:23:25 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:23:25,931 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:26 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:26,915 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:23:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:23:29,546 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:30,427 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:23:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:23:32,431 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:33 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:33,700 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:23:35 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:23:35,706 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:37,066 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:23:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:23:39,071 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:40 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:40,277 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:23:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:23:46,914 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:23:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:23:48,638 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:24:02 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:24:02,372 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:24:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:24:03,795 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:24:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:24:31,309 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:24:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:24:32,253 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:24:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:24:34,260 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:24:35 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:24:35,348 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:24:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:24:40,081 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:24:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:24:41,147 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:24:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:24:43,153 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:24:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:24:44,347 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:24:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:24:46,826 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:24:47 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:24:47,666 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:24:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:24:51,286 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:24:52 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:24:52,334 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:24:54 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:24:54,337 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:24:55 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:24:55,371 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:24:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:24:57,966 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:24:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:24:59,470 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:01,478 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:02,487 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:04,495 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:05 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:05,542 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:07 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:07,550 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:08 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:08,512 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:13,155 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:14,347 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:23 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:23,042 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:24 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:24,285 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:26,293 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:27 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:27,356 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:29,908 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:30,906 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:32,911 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:34,009 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:36,016 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:37,183 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:39,191 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:40 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:40,238 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:42 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:42,801 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:44,412 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:46,970 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:48,094 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:50 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:50,098 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:51,239 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:53,247 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:54,083 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:56,086 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:57,000 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:25:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:25:59,004 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:25:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:25:59,935 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:02 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:02,498 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:03,609 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:05 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:05,613 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:06,778 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:08,826 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:10,395 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:13,940 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:14,783 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:16,791 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:19 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:19,079 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:22,562 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:23 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:23,678 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:27,200 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:29,206 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:31,211 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:32,379 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:34,386 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:35 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:35,593 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:37 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:37,600 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:38,732 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:40,742 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:41,768 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:43,772 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:45,149 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:47,156 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:48,556 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:50 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:50,563 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:51,949 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:26:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:26:53,956 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:26:58 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:26:58,767 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:00 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:00,771 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:02,321 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:04,805 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:06,058 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:08,634 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:09,552 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:11,560 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:12 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:12,625 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:14 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:14,632 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:15 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:15,900 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:17 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:17,907 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:22 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:22,449 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:24,460 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:25 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:25,299 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:27,309 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:28 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:28,398 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:30 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:30,410 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:31 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:31,220 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:34,789 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:35 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:35,887 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:39,469 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:40 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:40,494 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:42 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:42,501 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:44,144 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:46,150 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:50,328 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:52,334 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:53 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:53,425 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:55,432 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:56 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:56,555 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:27:58 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:27:58,560 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:27:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:27:59,760 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:01,768 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:28:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:28:02,914 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:04,922 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:28:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:28:06,999 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:09 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:09,005 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:28:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:28:10,294 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:12 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:12,300 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:28:13 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:28:13,348 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:31,387 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:28:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:28:32,620 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:34,628 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:28:35 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:28:35,457 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:37 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:37,460 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:28:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:28:38,323 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:40,329 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:28:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:28:41,235 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:43,242 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:28:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:28:44,568 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:46,574 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:28:47 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:28:47,903 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:51,014 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:28:52 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:28:52,158 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:54 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:54,166 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:28:55 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:28:55,027 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:28:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:28:57,032 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:00 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:00,172 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:02 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:02,684 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:03,935 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:05 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:05,942 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:07 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:07,033 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:09 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:09,040 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:10,041 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:12 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:12,044 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:12 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:12,983 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:14 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:14,986 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:15 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:15,945 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:17 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:17,948 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:18 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:18,991 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:20,995 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:22 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:22,499 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:26,087 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:27 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:27,254 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:29,260 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:30,851 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:32,869 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:34,401 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:36,408 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:37,685 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:41 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:41,252 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:42 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:42,233 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:44,241 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:45,615 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:47,624 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:48,582 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:50 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:50,590 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:51,756 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:53,764 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:55 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:55,381 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:29:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:29:57,388 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:29:58 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:29:58,580 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:00 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:00,585 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:01 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:01,689 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:03 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:03,694 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:05 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:05,321 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:07 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:07,326 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:08 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:08,758 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:10 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:10,765 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:11 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:11,627 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:15 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:15,236 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:16 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:16,640 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:19,201 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:20,233 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:22,240 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:23 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:23,192 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:25 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:25,750 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:27 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:27,191 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:29,196 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:30,181 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:32,186 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:33 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:33,127 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:35 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:35,135 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:36 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:36,405 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:38 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:38,413 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:39 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:39,373 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:41 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:41,374 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:42 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:42,388 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:44,395 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:45,619 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:47,625 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:48,692 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:51,254 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:52 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:52,324 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:54 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:54,332 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:30:56 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:30:56,986 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:30:58 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:30:58,993 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:00 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:00,294 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:02 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:02,304 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:03,541 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:05 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:05,546 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:06,868 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:08,875 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:10,096 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:12 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:12,100 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:13 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:13,268 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:15 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:15,270 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:16 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:16,650 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:18,657 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:19 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:19,897 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:21 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:21,903 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:22 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:22,929 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:24,937 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:27 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:27,550 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:29,557 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:30,702 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:32,709 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:34,304 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:40,984 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:43 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:43,083 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:45 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:45,092 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:46 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:46,653 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:48 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:48,660 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:49 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:49,996 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:52,001 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:53 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:53,413 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:55,417 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:56 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:56,488 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:31:58 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:31:58,492 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:31:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:31:59,685 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:01,692 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:02,836 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:04,842 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:05 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:05,799 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:07 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:07,806 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:08 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:08,835 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:10 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:10,841 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:11 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:11,845 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:13,859 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:15 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:15,220 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:17 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:17,226 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:18 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:18,194 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:20,200 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:21,083 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:23 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:23,088 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:24 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:24,083 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:26,086 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:26 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:26,999 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:29,004 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:30,042 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:32,049 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:33 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:33,143 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:35 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:35,150 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:36 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:36,421 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:38 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:38,426 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:39 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:39,490 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:41 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:41,494 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:42 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:42,426 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:44,434 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:45,638 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:47,642 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:49 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:49,016 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:51,023 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:52 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:52,029 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:54 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:54,032 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:55 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:55,184 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:32:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:32:57,188 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:32:58 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:32:58,911 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:00 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:00,915 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:01 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:01,779 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:03 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:03,782 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:04 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:04,765 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:06 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:06,773 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:07 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:07,960 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:09 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:09,967 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:10,986 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:12 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:12,992 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:14,217 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:16,224 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:17 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:17,175 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:19,694 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:20,587 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:22,591 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:23 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:23,813 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:26,356 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:27 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:27,231 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:29,785 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:37,101 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:39,105 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:40 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:40,137 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:42 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:42,672 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:43 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:43,710 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:45 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:45,718 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:46 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:46,975 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:48 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:48,983 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:49 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:49,994 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:52,476 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:53 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:53,836 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:55,843 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:33:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:33:57,213 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:33:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:33:59,218 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:00 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:00,429 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:02 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:02,434 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:03,769 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:05 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:05,776 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:06,880 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:08,888 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:09,753 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:11,760 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:12 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:12,780 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:14 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:14,783 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:16 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:16,056 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:18,063 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:19 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:19,254 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:21 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:21,261 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:22 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:22,458 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:24,462 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:25 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:25,785 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:27,789 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:29,191 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:31,198 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:32,428 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:34,436 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:35 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:35,259 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:37 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:37,265 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:38,811 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:40,815 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:41,966 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:44,613 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:45,790 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:47,797 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:49 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:49,102 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:51,108 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:52 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:52,026 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:54 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:54,031 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:54,914 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:34:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:34:56,919 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:34:58 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:34:58,110 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:01,698 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:02,753 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:09 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:09,416 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:10,739 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:12 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:12,746 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:13 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:13,914 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:15 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:15,918 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:17 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:17,191 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:19,198 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:20,556 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:22,563 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:23 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:23,849 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:25 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:25,853 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:27 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:27,229 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:29 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:29,233 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:30,839 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:32,842 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:34,192 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:36,196 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:37,877 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:39,884 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:41,202 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:43,211 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:44,717 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:46,723 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:47 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:47,605 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:49,612 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:50,811 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:52,819 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:53 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:53,956 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:55,964 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:56 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:56,821 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:35:58 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:35:58,828 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:35:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:35:59,981 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:01,989 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:03 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:03,276 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:05 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:05,280 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:06,242 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:08,250 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:09,506 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:11,512 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:13 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:13,011 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:15 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:15,015 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:16 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:16,119 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:18,123 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:20,077 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:22,085 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:23 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:23,293 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:25 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:25,300 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:26 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:26,415 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:28 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:28,419 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:29,715 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:31,719 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:32,579 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:34,587 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:36 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:36,804 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:38 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:38,813 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:39 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:39,702 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:41 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:41,710 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:42 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:42,799 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:44,805 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:45,944 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:47,949 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:49 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:49,148 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:51,154 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:52 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:52,402 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:54 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:54,407 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:55 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:55,803 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:36:58 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:36:58,372 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:36:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:36:59,286 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:01,291 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:02,359 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:04,364 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:05 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:05,447 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:07 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:07,452 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:08 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:08,398 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:10 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:10,404 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:11 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:11,377 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:13,385 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:14,453 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:16,460 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:17 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:17,614 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:19,617 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:20,922 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:22,926 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:24 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:24,441 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:26,448 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:29,188 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:31,193 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:32,569 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:34,575 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:35 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:35,328 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:37 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:37,333 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:38,514 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:40,520 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:41,887 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:43,891 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:45,230 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:47,233 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:48,438 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:50 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:50,441 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:51,375 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:53,383 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:54,364 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:56,372 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:37:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:37:57,328 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:37:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:37:59,911 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:01 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:01,156 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:03 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:03,163 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:04 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:04,043 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:06 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:06,050 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:07 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:07,372 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:09 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:09,379 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:11 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:11,067 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:13,073 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:14,285 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:16,794 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:18 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:18,108 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:20,115 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:21,396 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:23 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:23,404 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:25 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:25,284 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:27,286 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:29,093 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:31,635 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:32,727 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:34,735 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:36 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:36,058 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:38 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:38,065 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:39 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:39,028 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:41 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:41,036 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:42 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:42,339 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:44,901 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:38:46 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:38:46,069 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:38:48 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:38:48,077 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:02,908 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:04,914 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:06,061 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:08,063 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:09,132 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:11,139 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:12 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:12,084 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:14 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:14,090 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:15 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:15,276 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:17 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:17,282 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:18 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:18,245 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:20,252 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:21,387 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:24,919 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:26 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:26,150 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:28 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:28,157 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:29,398 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:31,403 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:32,741 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:37 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:37,317 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:38,626 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:40,630 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:41,796 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:52,972 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:54,372 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:56,380 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:39:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:39:57,364 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:39:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:39:59,884 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:01 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:01,255 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:03 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:03,261 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:04 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:04,185 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:06 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:06,191 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:07 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:07,501 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:08,088 - lit_agent.identifiers.validators - WARNING - NCBI API returned status 429
13:40:10 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:10,159 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:11 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:11,417 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:13,425 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:14,365 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:16,372 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:17 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:17,389 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:19 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:19,396 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:25 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:25,156 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:27,164 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:28 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:28,190 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:30 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:30,194 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:31 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:31,292 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:33 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:33,301 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:34,638 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:36,643 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:37,813 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:39,821 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:40 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:40,674 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:42 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:42,679 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:43 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:43,752 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:45 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:45,757 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:46 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:46,825 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:49,422 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:50,500 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:53,056 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:54,303 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:56,308 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:40:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:40:57,656 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:40:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:40:59,663 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:04 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:04,602 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:06 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:06,609 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:07 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:07,919 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:09 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:09,927 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:10,804 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:13,800 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:14,993 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:16,997 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:18 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:18,483 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:20,489 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:21,438 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:23 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:23,444 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:25 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:25,957 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:27,963 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:29,324 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:31,330 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:32,308 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:34,312 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:35 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:35,269 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:37 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:37,277 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:38,845 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:41 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:41,374 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:42 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:42,587 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:44 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:44,593 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:45,706 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:47,710 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:48,574 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:50 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:50,581 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:51,671 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:53,795 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:54,650 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:56,658 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:41:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:41:57,691 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:41:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:41:59,700 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:01 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:01,377 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:03 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:03,386 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:04 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:04,757 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:06 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:06,765 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:14,176 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:16 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:16,183 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:17 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:17,145 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:20,733 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:21,634 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:25 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:25,278 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:26 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:26,975 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:28 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:28,979 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:30 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:30,535 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:32,541 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:33 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:33,632 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:36,212 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:37,521 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:39,524 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:40 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:40,601 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:42 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:42,608 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:43 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:43,974 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:45 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:45,978 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:46 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:46,982 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:50 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:50,541 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:51,675 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:53,682 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:54,732 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:56,737 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:42:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:42:57,658 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:42:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:42:59,664 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:01 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:01,059 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:03 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:03,065 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:04 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:04,080 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:06 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:06,087 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:06,969 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:08,976 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:10,330 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:12 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:12,872 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:21,737 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:24,275 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:25 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:25,755 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:27,758 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:28 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:28,762 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:32 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:32,280 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:33 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:33,331 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:36,884 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:38,246 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:40 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:40,771 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:41,979 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:43,986 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:45,274 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:47,280 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:49 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:49,594 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:51,601 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:52 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:52,606 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:54 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:54,612 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:55 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:55,757 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:43:58 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:43:58,004 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:43:59 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:43:59,226 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:01 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:01,233 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:02 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:02,691 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:04,698 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:05 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:05,776 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:08,259 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:09,617 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:11,625 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:12 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:12,612 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:15 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:15,146 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:16 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:16,289 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:18,295 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:19 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:19,687 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:21 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:21,690 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:22 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:22,700 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:24 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:24,705 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:31 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:31,497 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:33 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:33,502 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:35 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:35,077 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:37 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:37,081 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:38 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:38,355 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:41 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:41,852 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:43 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:43,071 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:45 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:45,074 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:46 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:46,140 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:48 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:48,148 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:49 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:49,109 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:51 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:51,675 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:53 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:53,206 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:55 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:55,209 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:44:56 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:44:56,481 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:44:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:44:59,000 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:00 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:00,230 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:02 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:02,235 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:07 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:07,150 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:11,740 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:12 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:12,827 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:14 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:14,831 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:16 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:16,142 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:18,715 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:20,054 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:22,061 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:23 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:23,109 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:27,689 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:29,354 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:31,361 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:32 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:32,860 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:34 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:34,867 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:36 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:36,519 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:38 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:38,525 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:41,206 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:43,214 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:45 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:45,447 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:47,455 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:48 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:48,387 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:50 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:50,900 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:51 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:51,761 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:53,764 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:55 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:55,157 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:45:57 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:45:57,165 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:45:58 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:45:58,206 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:46:00 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:46:00,624 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:46:01 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:46:01,508 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
13:57:15 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 13:57:15,819 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
13:57:17 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 13:57:17,441 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-11-06 14:01:06,205 - lit_agent.identifiers.validators - WARNING - NCBI API returned status 429
2025-11-06 14:01:07,325 - lit_agent.identifiers.validators - WARNING - NCBI API returned status 429
14:04:47 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:04:47,860 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:04:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:04:50,057 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:04:52 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:04:52,599 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:04:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:04:54,536 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:04 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:04,201 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:06 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:06,907 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:08 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:08,914 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:10 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:10,671 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:13,230 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:14 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:14,958 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:18 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:18,500 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:20 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:20,067 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:22 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:22,738 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:24 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:24,019 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:27,615 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:29 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:29,069 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:31 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:31,595 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:33 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:33,638 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:35 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:35,645 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:36 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:36,850 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:38 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:38,855 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:40 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:40,129 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:42 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:42,688 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:44,377 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:48 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:48,882 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:50 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:50,468 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:53 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:53,022 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:54,372 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:56,379 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:05:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:05:57,676 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:05:59 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:05:59,683 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:01 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:01,748 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:03 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:03,754 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:09 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:09,268 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:11 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:11,273 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:13 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:13,558 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:17 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:17,054 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:18 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:18,321 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:20 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:20,323 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:21,470 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:23 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:23,473 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:24 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:24,921 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:26 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:26,927 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:28 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:28,155 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:30 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:30,159 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:31 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:31,376 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:33 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:33,381 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:34 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:34,583 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:36 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:36,590 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:37 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:37,828 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:39 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:39,836 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:41 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:41,326 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:43 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:43,332 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:44 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:44,294 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:46 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:46,301 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:47 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:47,505 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:49 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:49,510 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:54 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:54,038 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:06:56 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:06:56,608 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:06:57 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:06:57,796 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:17:13 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:17:13,544 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:17:13,591 - openai._base_client - INFO - Retrying request to /chat/completions in 0.491146 seconds
14:17:15 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:17:15,249 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:17:17 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:17:17,258 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:17:21 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:17:21,516 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:17:27 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:17:27,186 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
14:17:28 - LiteLLM:INFO: utils.py:1302 - Wrapper: Completed Call, calling success_handler
2025-11-06 14:17:28,559 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
14:17:30 - LiteLLM:INFO: utils.py:3421 - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
2025-11-06 14:17:30,564 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-3.5-turbo; provider = openai
^CTraceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/Users/do12/Documents/GitHub/lit_agent/src/lit_agent/identifiers/validation_demo.py", line 381, in <module>
    report = run_validation_assessment_demo(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/src/lit_agent/identifiers/validation_demo.py", line 112, in run_validation_assessment_demo
    result = extract_identifiers_from_bibliography(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/src/lit_agent/identifiers/api.py", line 138, in extract_identifiers_from_bibliography
    topic_result = topic_validator.validate_topic_relevance(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/src/lit_agent/identifiers/topic_validator.py", line 97, in validate_topic_relevance
    result = self._analyze_with_llm(title, abstract, pmid)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/src/lit_agent/identifiers/topic_validator.py", line 140, in _analyze_with_llm
    response = litellm.completion(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1245, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/litellm/main.py", line 2125, in completion
    response = openai_chat_completions.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 673, in completion
    ) = self.make_sync_openai_chat_completion_request(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 471, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 217, in _receive_event
    data = self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/do12/Documents/GitHub/lit_agent/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 128, in read
    return self._sock.recv(max_bytes)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py", line 1233, in recv
    return self.read(buflen)
           ^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py", line 1106, in read
    return self._sslobj.read(len)
           ^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
